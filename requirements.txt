# Core ML & NLP
torch>=2.0.1,<3.0.0  # Core deep learning framework
transformers>=4.33.1,<5.0.0  # For utilities, comparison, tokenizers
tokenizers>=0.14.0,<1.0.0  # For custom tokenizer training
datasets>=2.14.5,<3.0.0  # For handling data efficiently
accelerate>=0.22.0,<1.0.0  # Helper for DDP and mixed precision
peft>=0.5.0,<1.0.0  # For LoRA implementation

# MLOps & Experiment Tracking
mlflow>=2.6.0,<3.0.0  # Experiment tracking and model registry
wandb>=0.15.0,<1.0.0  # Optional: Alternative experiment tracking

# Serving & API
fastapi>=0.103.1,<1.0.0  # API framework
uvicorn[standard]>=0.23.2,<1.0.0  # ASGI server
pydantic>=2.0.0,<3.0.0  # Data validation

# Utilities
pyyaml>=6.0.1,<7.0.0  # Configuration management
python-dotenv>=1.0.0,<2.0.0  # Environment variable management
numpy>=1.26.4,<2.0.0  # Numerical computations
scikit-learn>=1.4.2,<2.0.0  # Evaluation metrics
tqdm>=4.65.0,<5.0.0  # Progress bars
rich>=13.0.0,<14.0.0  # Rich terminal formatting

# Development & Testing
pytest>=7.0.0,<8.0.0  # Testing framework
black>=23.0.0,<24.0.0  # Code formatting
isort>=5.12.0,<6.0.0  # Import sorting
flake8>=6.0.0,<7.0.0  # Code linting
mypy>=1.0.0,<2.0.0  # Type checking

# Optional Dependencies
# Uncomment based on your needs:
# deepspeed>=0.9.0,<1.0.0  # For distributed training
# bitsandbytes>=0.41.0,<1.0.0  # For quantization
# nltk>=3.8.0,<4.0.0  # For text processing
# rouge_score>=0.1.2,<1.0.0  # For summarization evaluation